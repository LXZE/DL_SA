{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg.txt  unknown.pkl\t wn_neg_tok.pkl  wn_pos_int.npy  wn_pos.txt\n",
      "pos.txt  wn_neg_int.npy  wn_neg.txt\t wn_pos_tok.pkl  wongnai\n",
      "thai2vec  vec.npy\n"
     ]
    }
   ],
   "source": [
    "!ls \"../dataset\"\n",
    "!ls \"../model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import glob, re, time, sys\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, MaxPooling1D, Dropout, Flatten, Bidirectional, GRU, Embedding\n",
    "from keras import optimizers\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7187, 600)\n",
      "y_train shape: (7187, 2)\n",
      "x_val shape: (1797, 600)\n",
      "y_val shape: (1797, 2)\n",
      "7187 train samples\n",
      "1797 test samples\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001 # 1e-4\n",
    "num_steps = 10\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "data_dim = 300\n",
    "input_len = 100\n",
    "num_classes = 2\n",
    "\n",
    "# pos = np.load('pos.npy')\n",
    "# neg = np.load('neg.npy')\n",
    "\n",
    "pos = np.load('../dataset/wn_pos_int.npy')\n",
    "neg = np.load('../dataset/wn_neg_int.npy')\n",
    "\n",
    "word_vec = np.load('../model/vec.npy')\n",
    "\n",
    "x = np.concatenate((pos,neg), axis = 0)\n",
    "y = np.concatenate(\n",
    "\t(\n",
    "\t\tnp.full((pos.shape[0], 2), [0,1]),\n",
    "\t\tnp.full((neg.shape[0], 2), [1,0])\n",
    "\t), axis = 0\n",
    ")\n",
    "# x shape is (num_data, 100, 300) 100 is sentence length, 300 is vector dim\n",
    "# y shape is (num_data, 2)\n",
    "# y result are [1, 0] if it's a neg else it's [0, 1]\n",
    "x_train, x_val, y_train, y_val =  train_test_split(x,y, test_size=0.2)\n",
    "\n",
    "dropout = 0.25\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_val shape:', x_val.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'test samples')\n",
    "\n",
    "kernel_size = 5\n",
    "pool_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7187 samples, validate on 1797 samples\n",
      "Epoch 1/10\n",
      "7187/7187 [==============================] - 185s 26ms/step - loss: 0.5761 - acc: 0.7409 - val_loss: 0.5593 - val_acc: 0.7496\n",
      "Epoch 2/10\n",
      "7187/7187 [==============================] - 182s 25ms/step - loss: 0.5562 - acc: 0.7507 - val_loss: 0.5721 - val_acc: 0.7496\n",
      "Epoch 3/10\n",
      "7187/7187 [==============================] - 182s 25ms/step - loss: 0.5514 - acc: 0.7507 - val_loss: 0.5535 - val_acc: 0.7496\n",
      "Epoch 4/10\n",
      "7187/7187 [==============================] - 182s 25ms/step - loss: 0.5463 - acc: 0.7502 - val_loss: 0.5533 - val_acc: 0.7496\n",
      "Epoch 5/10\n",
      "7187/7187 [==============================] - 182s 25ms/step - loss: 0.5409 - acc: 0.7512 - val_loss: 0.5468 - val_acc: 0.7485\n",
      "Epoch 6/10\n",
      "7187/7187 [==============================] - 182s 25ms/step - loss: 0.5339 - acc: 0.7515 - val_loss: 0.5424 - val_acc: 0.7490\n",
      "Epoch 7/10\n",
      "7187/7187 [==============================] - 182s 25ms/step - loss: 0.5227 - acc: 0.7541 - val_loss: 0.5290 - val_acc: 0.7529\n",
      "Epoch 8/10\n",
      "7187/7187 [==============================] - 182s 25ms/step - loss: 0.4959 - acc: 0.7615 - val_loss: 0.5018 - val_acc: 0.7646\n",
      "Epoch 9/10\n",
      "7187/7187 [==============================] - 182s 25ms/step - loss: 0.4410 - acc: 0.7913 - val_loss: 0.5181 - val_acc: 0.7724\n",
      "Epoch 10/10\n",
      "7187/7187 [==============================] - 182s 25ms/step - loss: 0.4126 - acc: 0.8088 - val_loss: 0.4286 - val_acc: 0.8097\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 600, 300)          18000900  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 600, 256)          329472    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               123264    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 18,457,830\n",
      "Trainable params: 456,930\n",
      "Non-trainable params: 18,000,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Saved model to disk\n",
      "Prediction: 1\n",
      "Result: 1\n",
      "Prediction: 1\n",
      "Result: 1\n",
      "Prediction: 1\n",
      "Result: 1\n",
      "Prediction: 1\n",
      "Result: 1\n",
      "Prediction: 1\n",
      "Result: 1\n",
      "Prediction: 1\n",
      "Result: 1\n",
      "Prediction: 1\n",
      "Result: 1\n",
      "Prediction: 1\n",
      "Result: 1\n",
      "Prediction: 0\n",
      "Result: 1\n",
      "Prediction: 1\n",
      "Result: 1\n",
      "1797/1797 [==============================] - 14s 8ms/step\n",
      "loss: 0.42862032664837146\n",
      "acc: 80.96828047076265%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# model.add(Conv1D(64, kernel_size, activation='relu', input_shape=(input_len, data_dim)))\n",
    "# model.add(MaxPooling1D(pool_size=pool_size))\n",
    "model.add(Embedding(len(word_vec), 300, input_length=600, weights=[word_vec], trainable=False))\n",
    "model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "model.add(Bidirectional(GRU(64)))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr=learning_rate)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val))\n",
    "print(model.summary())\n",
    "\n",
    "model_name = 'model.h5'\n",
    "# if os.path.exists(model_name):\n",
    "# \tmodel.load_weights(model_name)\n",
    "# \tprint(\"Loaded model from disk\")\n",
    "# else:\n",
    "model.save_weights(model_name)\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "rand = np.random.choice(len(x_val), 10, replace=False)\n",
    "for i in rand:\n",
    "\tpre_x, pre_y = x_val[i], y_val[i]\n",
    "\tpre_x = pre_x.reshape(1, 600)\n",
    "\tres_y = model.predict_classes(pre_x, batch_size=1)\n",
    "\tprint('Prediction: {}'.format(res_y[0]))\n",
    "\tprint('Result: {}'.format(str(np.where(pre_y==1.)[0])[1]))\n",
    "\n",
    "score = model.evaluate(x_val, y_val, batch_size=batch_size)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], score[0]))\n",
    "print(\"{}: {}%\".format(model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
